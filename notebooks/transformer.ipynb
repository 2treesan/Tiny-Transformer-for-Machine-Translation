{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c052a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Tuỳ chọn) Cho Colab/Kaggle khi cần ép phiên bản:\n",
    "# Ghi chú: Nếu runtime đã có torch 2.x phù hợp thì có thể bỏ qua.\n",
    "\n",
    "# GPU (CUDA 12.1):\n",
    "# %pip install -q --index-url https://download.pytorch.org/whl/cu121 \\\n",
    "#     torch==2.2.* torchvision==0.17.* torchaudio==2.2.*\n",
    "\n",
    "# CPU only:\n",
    "# %pip install -q --index-url https://download.pytorch.org/whl/cpu \\\n",
    "#     torch==2.2.* torchvision==0.17.* torchaudio==2.2.*\n",
    "\n",
    "# Thư viện phụ trợ (khớp requirements.txt):\n",
    "# %pip install -q torchtext==0.17.* torchdata==0.7.* spacy==3.7.* altair==5.* GPUtil sacrebleu\n",
    "\n",
    "# (Tuỳ chọn) Tải model spaCy tiếng Anh/Đức nếu notebook này dùng tokenizer spaCy:\n",
    "# %python -m spacy download en_core_web_sm\n",
    "# %python -m spacy download de_core_news_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c1d153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ENV] torch=2.2.2+cpu | torchtext=0.17.2 | torchdata=0.7.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import log_softmax, pad  # Giữ nguyên API các cell sau đang dùng\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# torchtext/torchdata (giữ nguyên util đang dùng, dù bản mới khuyên DataPipes)\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "import torchtext.datasets as datasets\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import spacy\n",
    "import GPUtil\n",
    "\n",
    "# Thiết lập chung\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RUN_EXAMPLES = True\n",
    "\n",
    "# (Tuỳ chọn) Cảnh báo phiên bản để nhắc nâng cấp code về sau:\n",
    "try:\n",
    "    from importlib.metadata import version\n",
    "    _tv = version(\"torchtext\")\n",
    "    _td = version(\"torchdata\")\n",
    "    _pt = torch.__version__\n",
    "    print(f\"[ENV] torch={_pt} | torchtext={_tv} | torchdata={_td}\")\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae04749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_interactive_notebook():\n",
    "    return __name__ == \"__main__\"\n",
    "\n",
    "\n",
    "def show_example(fn, args=[]):\n",
    "    if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
    "        return fn(*args)\n",
    "\n",
    "\n",
    "def execute_example(fn, args=[]):\n",
    "    if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
    "        fn(*args)\n",
    "\n",
    "\n",
    "class DummyOptimizer(torch.optim.Optimizer):\n",
    "    def __init__(self):\n",
    "        self.param_groups = [{\"lr\": 0}]\n",
    "        None\n",
    "\n",
    "    def step(self):\n",
    "        None\n",
    "\n",
    "    def zero_grad(self, set_to_none=False):\n",
    "        None\n",
    "\n",
    "\n",
    "class DummyScheduler:\n",
    "    def step(self):\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90ef6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many\n",
    "    other models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
