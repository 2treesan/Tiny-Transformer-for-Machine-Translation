{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 01 · Train Tiny Transformer EN→VI (from scratch)\n\nPipeline tối giản: **dữ liệu → tiền xử lý → tokenization → mô hình (2E/2D) → huấn luyện → metrics → checkpoint**.\n> Lưu ý: Notebook này tự đủ, không phụ thuộc module ngoài `requirements.txt`."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 0) Imports & seed\nimport os, math, json, random, pathlib, time\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nPROJECT_ROOT = pathlib.Path(__file__).resolve().parents[1] if '__file__' in globals() else pathlib.Path.cwd().parents[1]\nDATA_RAW = PROJECT_ROOT / \"data\" / \"raw\"\nDATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\nCKPT_DIR = PROJECT_ROOT / \"models\" / \"checkpoints\"\nMETRIC_DIR = PROJECT_ROOT / \"reports\" / \"metrics\"\nOUT_DIR = PROJECT_ROOT / \"outputs\" / \"translations\"\nfor p in [CKPT_DIR, METRIC_DIR, OUT_DIR, DATA_PROCESSED]:\n    p.mkdir(parents=True, exist_ok=True)\n\nprint(\"Device:\", device)\nprint(\"Project root:\", PROJECT_ROOT)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) Nạp dữ liệu song ngữ\n- Đặt file song ngữ vào `data/raw/` (ví dụ: `article_en_vi.txt`).\n- Format tối giản: mỗi dòng là một cặp câu `en\\tvi` (tab giữa EN và VI)."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Đường dẫn ví dụ (bạn thay bằng file thật)\nraw_file = DATA_RAW / \"article_en_vi.txt\"\nif not raw_file.exists():\n    # Tạo file toy để notebook tự chạy (placeholder)\n    toy = [\n        \"Hello world\\tXin chào thế giới\",\n        \"This is a small dataset.\\tĐây là một tập dữ liệu nhỏ.\",\n        \"We build a tiny transformer.\\tChúng tôi xây một transformer nhỏ.\",\n        \"Attention is all you need.\\tSự chú ý là tất cả những gì bạn cần.\",\n    ]\n    raw_file.write_text(\"\\n\".join(toy), encoding=\"utf-8\")\nprint(\"Using data file:\", raw_file)\npairs = [line.strip().split(\"\\t\") for line in raw_file.read_text(encoding=\"utf-8\").splitlines() if \"\\t\" in line]\nprint(\"Num pairs:\", len(pairs))\npairs[:3]\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) Tokenization tối giản\nTa bắt đầu với token hoá whitespace (đủ cho toy). Sau này có thể nâng cấp BPE/SentencePiece nếu cần."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Whitespace tokenizer\ndef tokenize_ws(s): \n    return s.lower().strip().split()\n\n# Build vocab từ dữ liệu nhỏ\ndef build_vocab(texts, min_freq=1, specials=(\"<pad>\", \"<s>\", \"</s>\", \"<unk>\")):\n    from collections import Counter\n    cnt = Counter()\n    for t in texts:\n        cnt.update(tokenize_ws(t))\n    itos = list(specials)\n    itos += [w for w,f in cnt.items() if f>=min_freq and w not in specials]\n    stoi = {w:i for i,w in enumerate(itos)}\n    return stoi, itos\n\nen_texts = [en for en,_ in pairs]\nvi_texts = [vi for _,vi in pairs]\nsrc2i, i2src = build_vocab(en_texts)\ntgt2i, i2tgt = build_vocab(vi_texts)\n\nPAD, BOS, EOS, UNK = 0, 1, 2, 3\n\ndef encode_line(s, stoi, add_bos=False, add_eos=True, max_len=64):\n    toks = tokenize_ws(s)\n    ids = [stoi.get(t, UNK) for t in toks]\n    if add_bos: ids = [BOS] + ids\n    if add_eos: ids = ids + [EOS]\n    return ids[:max_len]\n\nprint(\"src_vocab_size:\", len(i2src), \"tgt_vocab_size:\", len(i2tgt))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Dataloader nhỏ"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def pad_batch(seqs, pad=PAD):\n    mx = max(len(s) for s in seqs)\n    out = [s + [pad]*(mx-len(s)) for s in seqs]\n    return torch.tensor(out, dtype=torch.long)\n\ndataset = [(encode_line(en, src2i, add_bos=False, add_eos=True),\n            encode_line(vi, tgt2i, add_bos=True,  add_eos=True)) for en,vi in pairs]\n\n# Simple train/dev split\nrandom.shuffle(dataset)\nn_dev = max(1, int(0.2*len(dataset)))\ndev_data = dataset[:n_dev]\ntrain_data = dataset[n_dev:]\n\ndef batches(data, bs=32):\n    for i in range(0, len(data), bs):\n        yield data[i:i+bs]\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Kiến trúc Transformer tối giản (2E/2D)\n- Multi-Head Attention, FFN, Positional Encoding.\n- Không dùng library `transformers`; chỉ PyTorch thuần."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Positional Encoding\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=5000):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe.unsqueeze(0))  # [1, max_len, d_model]\n    def forward(self, x):\n        x = x + self.pe[:, :x.size(1)]\n        return x\n\n# Scaled Dot-Product Attention\ndef attention(q, k, v, mask=None, dropout=None):\n    d_k = q.size(-1)\n    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n    if mask is not None:\n        scores = scores.masked_fill(mask==0, float(\"-inf\"))\n    attn = torch.softmax(scores, dim=-1)\n    if dropout is not None:\n        attn = dropout(attn)\n    return torch.matmul(attn, v), attn\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, h, d_model, dropout=0.1):\n        super().__init__()\n        assert d_model % h == 0\n        self.d_k = d_model // h\n        self.h = h\n        self.linear_q = nn.Linear(d_model, d_model)\n        self.linear_k = nn.Linear(d_model, d_model)\n        self.linear_v = nn.Linear(d_model, d_model)\n        self.linear_out = nn.Linear(d_model, d_model)\n        self.dropout = nn.Dropout(dropout)\n    def forward(self, query, key, value, mask=None):\n        bs = query.size(0)\n        def split(x):\n            return x.view(bs, -1, self.h, self.d_k).transpose(1,2)\n        q = split(self.linear_q(query))\n        k = split(self.linear_k(key))\n        v = split(self.linear_v(value))\n        if mask is not None:\n            mask = mask.unsqueeze(1)  # broadcast over heads\n        x, attn = attention(q, k, v, mask=mask, dropout=self.dropout)\n        x = x.transpose(1,2).contiguous().view(bs, -1, self.h*self.d_k)\n        return self.linear_out(x)\n\nclass PositionwiseFFN(nn.Module):\n    def __init__(self, d_model, d_ff, dropout=0.1):\n        super().__init__()\n        self.w1 = nn.Linear(d_model, d_ff)\n        self.w2 = nn.Linear(d_ff, d_model)\n        self.dropout = nn.Dropout(dropout)\n    def forward(self, x):\n        return self.w2(self.dropout(F.relu(self.w1(x))))\n\nclass EncoderLayer(nn.Module):\n    def __init__(self, d_model, self_h, d_ff, dropout=0.1):\n        super().__init__()\n        self.self_attn = MultiHeadAttention(self_h, d_model, dropout)\n        self.ffn = PositionwiseFFN(d_model, d_ff, dropout)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.drop = nn.Dropout(dropout)\n    def forward(self, x, src_mask):\n        x2 = self.self_attn(x, x, x, src_mask)\n        x = self.norm1(x + self.drop(x2))\n        x2 = self.ffn(x)\n        x = self.norm2(x + self.drop(x2))\n        return x\n\nclass DecoderLayer(nn.Module):\n    def __init__(self, d_model, self_h, cross_h, d_ff, dropout=0.1):\n        super().__init__()\n        self.self_attn = MultiHeadAttention(self_h, d_model, dropout)\n        self.cross_attn = MultiHeadAttention(cross_h, d_model, dropout)\n        self.ffn = PositionwiseFFN(d_model, d_ff, dropout)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.norm3 = nn.LayerNorm(d_model)\n        self.drop = nn.Dropout(dropout)\n    def forward(self, x, memory, tgt_mask, src_mask):\n        x2 = self.self_attn(x, x, x, tgt_mask)\n        x = self.norm1(x + self.drop(x2))\n        x2 = self.cross_attn(x, memory, memory, src_mask)\n        x = self.norm2(x + self.drop(x2))\n        x2 = self.ffn(x)\n        x = self.norm3(x + self.drop(x2))\n        return x\n\ndef subsequent_mask(sz):\n    # mask cho decoder để cấm nhìn tương lai\n    attn_shape = (1, sz, sz)\n    subsequent = torch.triu(torch.ones(attn_shape), diagonal=1).type(torch.uint8)\n    return (subsequent == 0)\n\nclass TinyTransformer(nn.Module):\n    def __init__(self, src_vocab, tgt_vocab, d_model=128, N=2, h=4, d_ff=256, dropout=0.1):\n        super().__init__()\n        self.src_embed = nn.Embedding(src_vocab, d_model, padding_idx=PAD)\n        self.tgt_embed = nn.Embedding(tgt_vocab, d_model, padding_idx=PAD)\n        self.pos = PositionalEncoding(d_model)\n        self.enc_layers = nn.ModuleList([EncoderLayer(d_model, h, d_ff, dropout) for _ in range(N)])\n        self.dec_layers = nn.ModuleList([DecoderLayer(d_model, h, h, d_ff, dropout) for _ in range(N)])\n        self.proj = nn.Linear(d_model, tgt_vocab)\n    def encode(self, src, src_mask):\n        x = self.pos(self.src_embed(src))\n        for layer in self.enc_layers:\n            x = layer(x, src_mask)\n        return x\n    def decode(self, tgt, memory, tgt_mask, src_mask):\n        x = self.pos(self.tgt_embed(tgt))\n        for layer in self.dec_layers:\n            x = layer(x, memory, tgt_mask, src_mask)\n        return x\n    def forward(self, src, tgt, src_mask, tgt_mask):\n        memory = self.encode(src, src_mask)\n        dec = self.decode(tgt, memory, tgt_mask, src_mask)\n        return self.proj(dec)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5) Huấn luyện tối giản\n- Loss: CrossEntropy (tgt bị dịch trái 1 token).\n- Optim: Adam.\n- Metrics: loss/accuracy; thêm BLEU nhỏ trên dev."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def make_src_mask(src):\n    return (src != PAD).unsqueeze(1).unsqueeze(2)  # [B,1,1,S]\n\ndef make_tgt_mask(tgt):\n    b, t = tgt.size()\n    pad_mask = (tgt != PAD).unsqueeze(1).unsqueeze(2)  # [B,1,1,T]\n    sub_mask = subsequent_mask(t).to(tgt.device)        # [1,T,T]\n    return pad_mask & sub_mask\n\ndef shift_tgt(tgt):\n    # input to decoder (tgt_in) and labels (tgt_out)\n    return tgt[:, :-1], tgt[:, 1:]\n\nmodel = TinyTransformer(len(i2src), len(i2tgt)).to(device)\noptim = torch.optim.Adam(model.parameters(), lr=3e-4)\ncriterion = nn.CrossEntropyLoss(ignore_index=PAD)\n\ndef run_epoch(data, train=True, bs=32):\n    model.train(train)\n    total_loss, total_tok, correct = 0.0, 0, 0\n    for batch in batches(data, bs):\n        src, tgt = zip(*batch)\n        src = pad_batch(list(src)).to(device)\n        tgt = pad_batch(list(tgt)).to(device)\n        tgt_in, tgt_out = shift_tgt(tgt)\n        src_mask = make_src_mask(src)\n        tgt_mask = make_tgt_mask(tgt_in)\n        logits = model(src, tgt_in, src_mask, tgt_mask)\n        # logits: [B,T,V]\n        loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n        if train:\n            optim.zero_grad(); loss.backward(); optim.step()\n        total_loss += loss.item() * tgt_out.ne(PAD).sum().item()\n        preds = logits.argmax(-1)\n        mask = tgt_out.ne(PAD)\n        correct += (preds[mask] == tgt_out[mask]).sum().item()\n        total_tok += mask.sum().item()\n    return total_loss/ max(1,total_tok), correct/ max(1,total_tok)\n\nEPOCHS = 5\nhistory = {\"train_loss\":[], \"train_acc\":[], \"dev_loss\":[], \"dev_acc\":[]}\nfor ep in range(1, EPOCHS+1):\n    tr_loss, tr_acc = run_epoch(train_data, train=True, bs=16)\n    dv_loss, dv_acc = run_epoch(dev_data, train=False, bs=16)\n    history[\"train_loss\"].append(tr_loss); history[\"train_acc\"].append(tr_acc)\n    history[\"dev_loss\"].append(dv_loss); history[\"dev_acc\"].append(dv_acc)\n    print(f\"Epoch {ep:02d} | train loss {tr_loss:.4f} acc {tr_acc:.3f} | dev loss {dv_loss:.4f} acc {dv_acc:.3f}\")\n\n# Lưu checkpoint & metrics\nckpt_path = CKPT_DIR / \"tiny_transformer_en2vi.pt\"\ntorch.save({\"model\": model.state_dict(),\n            \"src2i\": src2i, \"i2src\": i2src,\n            \"tgt2i\": tgt2i, \"i2tgt\": i2tgt},\n           ckpt_path)\n(json.dumps(history, indent=2))\nmetrics_path = METRIC_DIR / \"history.json\"\nmetrics_path.write_text(json.dumps(history, ensure_ascii=False, indent=2), encoding=\"utf-8\")\nprint(\"Saved:\", ckpt_path, \"and\", metrics_path)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6) BLEU (dev nhỏ)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from sacrebleu.metrics import BLEU\n\ndef greedy_decode(model, src_ids, max_len=64):\n    model.eval()\n    src = torch.tensor([src_ids], dtype=torch.long, device=device)\n    src_mask = make_src_mask(src)\n    memory = model.encode(src, src_mask)\n    ys = torch.tensor([[BOS]], dtype=torch.long, device=device)\n    for _ in range(max_len-1):\n        tgt_mask = make_tgt_mask(ys)\n        out = model.decode(ys, memory, tgt_mask, src_mask)\n        prob = model.proj(out)[:, -1, :].softmax(-1)\n        next_token = prob.argmax(-1).item()\n        ys = torch.cat([ys, torch.tensor([[next_token]], device=device)], dim=1)\n        if next_token == EOS:\n            break\n    return ys.squeeze(0).tolist()\n\ndef detok(ids, i2w):\n    toks = []\n    for i in ids:\n        if i in (PAD, BOS): continue\n        if i == EOS: break\n        toks.append(i2w[i])\n    return \" \".join(toks)\n\nbleu = BLEU()\nrefs, hyps = [], []\nfor src_ids, tgt_ids in dev_data:\n    pred_ids = greedy_decode(model, src_ids)\n    refs.append([detok(tgt_ids, i2tgt)])\n    hyps.append(detok(pred_ids, i2tgt))\n\nscore = bleu.corpus_score(hyps, refs)\nprint(\"DEV BLEU:\", score)\n# Lưu sample\nsample_path = OUT_DIR / \"dev_samples.txt\"\nsample = \"\\n\".join([f\"HYP: {h}\\nREF: {r[0]}\" for h,r in zip(hyps, refs)])\nsample_path.write_text(sample, encoding=\"utf-8\")\nprint(\"Saved samples to\", sample_path)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "> Notebook kết thúc: bạn đã có **checkpoint** và **metrics** để dùng trong demo."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}